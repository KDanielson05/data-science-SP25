---
title: "Michelson Speed-of-light Measurements"
author: "Katherine Danielson"
date: 02-09-2025
output: 
  github_document:
    toc: true
prerequisites:
  - e-data02-derive
editor_options: 
  markdown: 
    wrap: 72
---

*Purpose*: When studying physical problems, there is an important
distinction between *error* and *uncertainty*. The primary purpose of
this challenge is to dip our toes into these factors by analyzing a real
dataset.

*Reading*: [Experimental Determination of the Velocity of
Light](https://play.google.com/books/reader?id=343nAAAAMAAJ&hl=en&pg=GBS.PA115)
(Optional)

<!-- include-rubric -->

# Grading Rubric

<!-- -------------------------------------------------- -->

Unlike exercises, **challenges will be graded**. The following rubrics
define how you will be graded, both on an individual and team basis.

## Individual

<!-- ------------------------- -->

| Category | Needs Improvement | Satisfactory |
|-------------------|----------------------------|-------------------------|
| Effort | Some task **q**'s left unattempted | All task **q**'s attempted |
| Observed | Did not document observations, or observations incorrect | Documented correct observations based on analysis |
| Supported | Some observations not clearly supported by analysis | All observations clearly supported by analysis (table, graph, etc.) |
| Assessed | Observations include claims not supported by the data, or reflect a level of certainty not warranted by the data | Observations are appropriately qualified by the quality & relevance of the data and (in)conclusiveness of the support |
| Specified | Uses the phrase "more data are necessary" without clarification | Any statement that "more data are necessary" specifies which *specific* data are needed to answer what *specific* question |
| Code Styled | Violations of the [style guide](https://style.tidyverse.org/) hinder readability | Code sufficiently close to the [style guide](https://style.tidyverse.org/) |

## Submission

<!-- ------------------------- -->

Make sure to commit both the challenge report (`report.md` file) and
supporting files (`report_files/` folder) when you are done! Then submit
a link to Canvas. **Your Challenge submission is not complete without
all files uploaded to GitHub.**

```{r message=FALSE, warning=FALSE}
# Libraries
library(tidyverse)
library(googlesheets4)

url <- "https://docs.google.com/spreadsheets/d/1av_SXn4j0-4Rk0mQFik3LLr-uf0YdA06i3ugE6n-Zdo/edit?usp=sharing"

# Parameters
LIGHTSPEED_VACUUM    <- 299792.458 # Exact speed of light in a vacuum (km / s)
LIGHTSPEED_MICHELSON <- 299944.00  # Michelson's speed estimate (km / s)
LIGHTSPEED_PM        <- 51         # Michelson error estimate (km / s)
```

*Background*: In 1879 Albert Michelson led an experimental campaign to
measure the speed of light. His approach was a development upon the
method of Foucault[3], and resulted in a new estimate of
$v_0 = 299944 \pm 51$ kilometers per second (in a vacuum). This is very
close to the modern *exact* value of `r LIGHTSPEED_VACUUM`. In this
challenge, you will analyze Michelson's original data, and explore some
of the factors associated with his experiment.

I've already copied Michelson's data from his 1880 publication; the code
chunk below will load these data from a public googlesheet.

*Aside*: The speed of light is *exact* (there is **zero error** in the
value `LIGHTSPEED_VACUUM`) because the meter is actually
[*defined*](https://en.wikipedia.org/wiki/Metre#Speed_of_light_definition)
in terms of the speed of light!

```{r read-sheet}
## Note: No need to edit this chunk!
gs4_deauth()
ss <- gs4_get(url)
df_michelson <-
  read_sheet(ss) %>%
  select(Date, Distinctness, Temp, Velocity) %>%
  mutate(Distinctness = as_factor(Distinctness))

df_michelson %>% 
  glimpse()
```

*Data dictionary*:

-   `Date`: Date of measurement
-   `Distinctness`: Distinctness of measured images: 3 = good, 2 = fair,
    1 = poor
-   `Temp`: Ambient temperature (Fahrenheit)
-   `Velocity`: Measured speed of light (km / s)

### **q1** Re-create the following table (from Michelson (1880), pg. 139) using `df_michelson` and `dplyr`. Note that your values *will not* match those of Michelson *exactly*; why might this be?

| Distinctness | n   | MeanVelocity |
|--------------|-----|--------------|
| 3            | 46  | 299860       |
| 2            | 39  | 299860       |
| 1            | 15  | 299810       |

```{r q1-task}
## TODO: Compute summaries
df_q1 <-
  df_michelson %>% 
  group_by(Distinctness) %>% 
  summarize(
    n = n(),
    MeanVelocity = mean(Velocity)
  )
df_q1 %>%
  arrange(desc(Distinctness)) %>%
  knitr::kable()
```

**Observations**:

-   Observations:

    -   The most observations (46) fell into the "good" distinctness
        category, with the next most seen in the "fair" quality and the
        least falling into the "poor" distinctness quality." When
        looking at the MeanVelocity in relation to the distinctness, the
        MeanVelocity value is quite close between the distinctness 2 and
        distinctness 3; however, there is a much larger gap between the
        distinctness 1 and 2. Additionally, distinctness 3, the "highest
        quality" data captures, appear to have the highest MeanVelocity.
        As we discover later, Michelson's value for the speed of light
        is higher than that of the actual speed of light. It would be
        interesting to learn more about what made a capture "good"
        versus "poor" to see if the "poor" captures actually were the
        better captures–as the MeanVelocity of the "poor" captures is
        closer to the actual speed of light.

-   Differing from Michelson's Data:

    -   The main idea that I believe may contribute to the difference
        between my data and Michelson's data could be a combination of
        rounding and siginficant figures. The majority of the time in
        science, significant figures are introduced to as calculations
        and values can not be truly verified down to the decimal place.
        In this case, with calculations of the speed of sound, it is
        likely that there is no accuracy down to the ones and tenth
        places. Thus, the values are rounded to the tens place. (ex. The
        MeanVelocity value of 299861.7 is seen as 299860 in Michelson's
        calculations.)

The `Velocity` values in the dataset are the speed of light *in air*;
Michelson introduced a couple of adjustments to estimate the speed of
light in a vacuum. In total, he added $+92$ km/s to his mean estimate
for `VelocityVacuum` (from Michelson (1880), pg. 141). While the
following isn't fully rigorous ($+92$ km/s is based on the mean
temperature), we'll simply apply this correction to all the observations
in the dataset.

### **q2** Create a new variable `VelocityVacuum` with the $+92$ km/s adjustment to `Velocity`. Assign this new dataframe to `df_q2`.

```{r q2-task}
## TODO: Adjust the data, assign to df_q2
df_q2 <-
  df_michelson %>% 
  mutate(
    VelocityVacuum = (Velocity + 92)
  )
df_q2
```

As part of his study, Michelson assessed the various potential sources
of error, and provided his best-guess for the error in his
speed-of-light estimate. These values are provided in
`LIGHTSPEED_MICHELSON`---his nominal estimate---and
`LIGHTSPEED_PM`---plus/minus bounds on his estimate. Put differently,
Michelson believed the true value of the speed-of-light probably lay
between `LIGHTSPEED_MICHELSON - LIGHTSPEED_PM` and
`LIGHTSPEED_MICHELSON + LIGHTSPEED_PM`.

Let's introduce some terminology:[2]

-   **Error** is the difference between a true value and an estimate of
    that value; for instance `LIGHTSPEED_VACUUM - LIGHTSPEED_MICHELSON`.
-   **Uncertainty** is an analyst's *assessment* of the error.

Since a "true" value is often not known in practice, one generally does
not know the error. The best they can do is quantify their degree of
uncertainty. We will learn some means of quantifying uncertainty in this
class, but for many real problems uncertainty includes some amount of
human judgment.[2]

### **q3** Compare Michelson's speed of light estimate against the modern speed of light value. Is Michelson's estimate of the error (his uncertainty) greater or less than the true error?

```{r q3-task}
## TODO: Compare Michelson's estimate and error against the true value
## Your code here!
true_error <-                               #assign error to true_error
  LIGHTSPEED_VACUUM - LIGHTSPEED_MICHELSON 
true_error

michelson_error <-                          #assign michelson error
  LIGHTSPEED_PM
michelson_error

abs(true_error) == abs(michelson_error)     #determine if the errors are the same
abs(true_error) < abs(michelson_error)      #determine if michelson_error is larger
abs(true_error) > abs(michelson_error)      #determine if true_error is larger

difference <-                               #difference in the error and uncertainty
  abs(true_error) - abs(michelson_error)
difference
```

**Observations**: - Is Michelson's estimate of the error (his
uncertainty) greater or less than the true error?- Make a quantitative
comparison between Michelson's uncertainty and his error.

-   Michelson's uncertainty (estimate of the error) was less than the
    true error.
-   Michelson's uncertainty had bounds that were too small–only 51 km/s
    above or below his estimate. Comparatively, the true error was
    151.542 km/s different than his estimate. His value for light speed
    was too high. The true error was 100.542 km/s different than his
    uncertainty. The large reason why Michelson's data was so far off
    from the true lights speed is likely a combination of temperature
    impact on Michelson's equipment and an over-compensation for the
    change from Velocity to VelocityVacuum.

The following plot shows all of Michelson's data as a [control
chart](https://en.wikipedia.org/wiki/Control_chart); this sort of plot
is common in manufacturing, where it is used to help determine if a
manufacturing process is under [statistical
control](https://en.wikipedia.org/wiki/Statistical_process_control).
Each dot is one of Michelson's measurements, and the grey line connects
the mean taken for each day. The same plot also shows simulated data
using a probability model. We'll get into statistics later in the
course; for now, let's focus on understanding what real and simulated
data tend to look like.

### **q4** Inspect the following plot with the `Real` Michelson data and `Simulated` data from a probability model. Document the similarities and differences between the data under *observe* below.

```{r q4-cf-real-simulated}
## Note: No need to edit this chunk!
## Calibrate simulated data
v_mean <-
  df_q2 %>%
  summarize(m = mean(VelocityVacuum)) %>%
  pull(m)
v_sd <-
  df_q2 %>%
  summarize(s = sd(VelocityVacuum)) %>%
  pull(s)

## Visualize
set.seed(101)
df_q2 %>%
  mutate(Simulated = rnorm(n(), mean = v_mean, sd = v_sd)) %>%
  rename(Real = VelocityVacuum) %>%
  pivot_longer(
    cols = c(Simulated, Real),
    names_to = "source",
    values_to = "velocity"
  ) %>%

  ggplot(aes(Date, velocity)) +
  geom_hline(
    yintercept = LIGHTSPEED_MICHELSON,
    linetype = "dotted"
  ) +
  geom_hline(
    yintercept = LIGHTSPEED_MICHELSON - LIGHTSPEED_PM,
    linetype = "dashed"
  ) +
  geom_hline(
    yintercept = LIGHTSPEED_MICHELSON + LIGHTSPEED_PM,
    linetype = "dashed"
  ) +

  geom_line(
    data = . %>%
      group_by(Date, source) %>%
      summarize(velocity_mean = mean(velocity)),
    mapping = aes(y = velocity_mean),
    color = "grey50"
  ) +
  geom_point(
    mapping = aes(y = velocity),
    size = 0.8
  ) +

  facet_grid(source~.) +
  theme_minimal() +
  labs(
    x = "Date of Measurement (1879)",
    y = "Velocity (in Vacuum)"
  )
```

**Observations**: Similarities & Differences

-   **Similarities**

    -   The Real and Simulated data both center around the Michelson
        data. This means they both contain a dotted line that represents
        the speed of light calculated based on the data collected. This
        dotted line helps to represent a common value that the data
        mostly revolves around. Additionally, both the Real and
        Simulated data contained dashed lines which represent the
        "error" bars–the 51 km/s up and down from Michelson's
        computation of the speed of light. For both the Real and
        Simulated data, the daily means generally fall within these
        lines. Additionally, both the Real and Simulated experiments
        have some days where there is clustering between the capture
        values and other days where most captures are highly spread out
        for velocity values.

-   **Differences**

    -   One of the main differences that can be seen is the
        "progression" or lack thereof in the experiment. When looking at
        the Real experiment data, the few times that the daily mean does
        not fall within Michelson's uncertainty, most all of them fall
        within the beginning dates of data capture and are very volatile
        differences. Comparatively, the Simulated data is more
        consistently seen within the uncertainty and generally only
        exceeds in minor amounts near the ending of the experiment. This
        can likely be tied to human error versus machine simulation.
        While it is hard to say for sure, Michelson likely got better at
        capturing data and limiting error–hence the greater clustering
        of data and consistency of the mean within the uncertainty near
        the end. However, as a machine holds no such "training" during
        simulations, the variation of data is seen consistently
        throughout the collection time frame. In order to better
        understand this, more data is needed. This data can be found
        through a combination of understanding the other variables
        within the data set and doing additional outside research to see
        the collection equipment and methods used.

### **q5** You have access to a few other variables. Construct a **at least three** visualizations of `VelocityVacuum` against these other factors. Are there other patterns in the data that might help explain the difference between Michelson's estimate and `LIGHTSPEED_VACUUM`?

```{r}
df_q2 %>% 
  group_by(Distinctness) %>% 
  ggplot(aes(Distinctness, VelocityVacuum)) +
  geom_boxplot(notch = TRUE) +                        #used the notch feature to help determine signifcant variance
  labs(title = "Veloctiy Vacuum and Distinctness")
```

**Observations**:

-   Distinctness appears at first to have some difference in the
    VelocityVacuum; however, there is not signifcant variance. To
    determine this, it was necessary to use the notch = TRUE feature of
    the box plot. When the notches of box plots overlap, it means the
    medians are not statistically significantly different. Additionally,
    this can be understood through a large level of variation seen
    through the long whiskers of each distinctness level. Thus, while it
    may appear like the distinctness value may have some impact at
    first, the distinctness likely does not actually play a role in the
    difference between Michelson's data and the true LIGHTSPEED_VACUUM
    data.

```{r}
df_q2 %>% 
  ggplot(aes(Temp, VelocityVacuum)) +
  geom_line() +
  labs(title = "Velocity Vacuum vs. Temperature")
```

**Observations**:

-   After discovering that distinctness likely does not have an impact
    on the difference between Michelson's data and the true
    LIGHTSPEED_VACUUM data, I wanted to look towards temperature. When
    looking at the overarching trend of VelocityVacuum compared to Temp,
    while there is a large amount of variation, there is an upward
    linear trend showing the progression of increasing VelocityVacuum as
    temperature increases. To determine if this has a true impact, more
    data is needed on the type of instrumentation he used an the
    conditions. While temperature should not have much if any influence
    on the speed of light, it can influence equipment. As Michelson's
    equipment was likely less accurate and highly temperature-sensitive,
    these fluctuations can lead to different readings. Additionally,
    with increasing temperature, the refractive index of air decreases
    slightly, meaning the readings can increase slightly and be slightly
    more similar to that of a vacuum. Thus, not only was Michelson's
    addition of 92 km/s to account for vacuum conditions too high to
    begin with, but the increased temperatures should have been adjusted
    slightly less.

```{r}
df_q2 %>% 
  ggplot(aes(Date, VelocityVacuum, color = Distinctness)) +
  geom_point() +
  geom_smooth(se = TRUE, color = "black") +
  labs(title = "Velocity Vacuum Data Over Date Collected")

```

**Observations**:

-   Right off the bat, there does not appear to be a trend between date
    and VelocityVacuum. VelocityVacuum appears to be higher during the
    earlier dates for data collection–it would be interesting to see if
    there was a change in the methods of collection over time.
    Additionally, it appears that Michelson generally had similar
    distinctness levels for data collection during a day. For example,
    the majority of his "poor" distinctness data points were all
    collected on the same day, and "good" and "okay" generally tend to
    be captured on a day and occasionally mixed.

## Bibliography

-   [1] Michelson, [Experimental Determination of the Velocity of
    Light](https://play.google.com/books/reader?id=343nAAAAMAAJ&hl=en&pg=GBS.PA115)
    (1880) 
-   [2] Henrion and Fischhoff, [Assessing Uncertainty in Physical
    Constants](https://www.cmu.edu/epp/people/faculty/research/Fischoff-Henrion-Assessing%20uncertainty%20in%20physical%20constants.pdf)
    (1986) 
-   [3] BYU video about a [Fizeau-Foucault
    apparatus](https://www.youtube.com/watch?v=Ik5ORaaeaME), similar to
    what Michelson used.
